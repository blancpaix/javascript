import { createServer } from 'http';

const { pid } = process;

const server = createServer((req, res) => {
  let i = 1e7;
  while (i > 0) {
    i--
  };
  console.log(`Handling request from ${pid}`);
  res.end(`Hello from ${pid}`);
});

const port = Number.parseInt(process.env.PORT || process.argv[2]) || 8080;

server.listen(port, () => console.log(`Server on ${pid}`));

/*



12-2-2 상태 저장 통신 다루기
  클러스터 인스턴스들은 상태가 공유되지 않음
  >> 상태 저장이 필요 (세션 처리에서...)

  Ex) 세선#1 요청, 인스턴스#1에 세션 저장. 로드밸런스로 인스턴스#2에 접속

  s1) 여러 인스턴스 상태 공유
    모든 인스턴스에서 상태 공유 - PostgreSQL, mongoDB, CouchDB, Redis (Memcached)
    패턴 적용하기 위해 상당량을 리팩토링해야 함. 라이브러리 사용하는것도 괜찮
    리팩토링 불가 시 영향도가 덜한 고정 로드 밸런싱 (고정 세션) 추천

    고정 로드 밸런싱 - sticky-session
      로드밸런서가 세션과 관련된 모든 요청을 지정된 인스턴스로 라우팅되도록 함
      { session, server } 구조 db 저장
      로드밸런서가 특정 인스턴스로 매핑 생성, 알고리듬 우회해서 해당 인스턴스 선택
      세션ID 검사가 필요 (일반적으로 어플 또는 로드밸런서 자체의 쿠기에 포함됨)

      더 간단한 방법은 IP 주소를 사용, => 정보 저장 필요가 없음
      (다만 다른 네트워크로 로밍 과 같이 잦은 ip 변경에는 부적합)
      

      단점
        모든 인스턴스가 동일...
        다른 인스턴스가 멈춘 인스턴스를 대체하는 장점 대부분을 무효화..??
        따라서 고정 로드밸런싱을 피하고 공유 저장소에 세션 상태를 저정하는것이 좋음
      
12-2-3 역방향 프록시 확장 - [Nginx], HAProxy, Node.js 깁나 프로시, 클라우드 기반 프록시
  독립 실행형 인스턴스 => 역방향 프록시, 인스턴스 접근을 제공해서 트래픽 분산
  마스터 프로세스 없음, 그냥 단순히 프로세스의 집합으로 구성되어 있고 단일 액세스 포인트 제공
  요청이 있으면 대상 서버에 보내고 .... 등등
  역방향 프록시는 로드밸런서로도 사용 가능

  node 의 경우 클러스터 모듈 대신 이것을 성택하는 이유
  1. 여러 시스템에 부하 분산 가능
  2. 시장에서 가장 널리되는 역방향 프록시 = 고정 로드 밸런싱 지원???
  3. 언어, 플랫폼 관계 없이 라우팅 가능
  4. 로드 밸런싱 알고리듬 선택 가능
  5. URL 재작성, 캐싱, sSL 종료지점 ,보안 기능 등 추가 기능으로 완전한 웹 서버 기능 제공

  필요시 클러스터 모듈을 역방향 프로시와 결합 가능
  클러스터 => 시스템 수직 확장
  역방향 프록시 => 수평으로 확장


  Nginx 를 사용한 로드 밸런싱
    cluster로 여러 인스턴스 시작안할거니까 커맨드라인 인자를 사용해 수신포트 지정 함... 코드 직접 작성!
    이렇게 해서 여러 인스턴스 시작 가능
    nginX 와 여러 인스턴스간 통신 필요,

    충돌 시 자동 재시작 필요 - [forever], systemd, monit, Kuvernetes (Docker, Nomad, Swarm... 컨테이너 기반 런티임)


node 4개 실행
PS C:\Users\Smart\JS\Node\12_scalability\01_simple_http> npx autocannon -c 200 -d 10 http://localhost:8080
Running 10s test @ http://localhost:8080
200 connections

┌─────────┬────────┬────────┬────────┬────────┬───────────┬──────────┬────────┐    
│ Stat    │ 2.5%   │ 50%    │ 97.5%  │ 99%    │ Avg       │ Stdev    │ Max    │    
├─────────┼────────┼────────┼────────┼────────┼───────────┼──────────┼────────┤    
│ Latency │ 238 ms │ 390 ms │ 533 ms │ 558 ms │ 390.16 ms │ 79.97 ms │ 601 ms │    
└─────────┴────────┴────────┴────────┴────────┴───────────┴──────────┴────────┘    
┌───────────┬─────────┬─────────┬─────────┬─────────┬─────────┬─────────┬─────────┐
│ Stat      │ 1%      │ 2.5%    │ 50%     │ 97.5%   │ Avg     │ Stdev   │ Min     │
├───────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Req/Sec   │ 459     │ 459     │ 504     │ 588     │ 507.9   │ 35.93   │ 459     │
├───────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Bytes/Sec │ 71.2 kB │ 71.2 kB │ 78.1 kB │ 91.2 kB │ 78.7 kB │ 5.57 kB │ 71.1 kB │
└───────────┴─────────┴─────────┴─────────┴─────────┴─────────┴─────────┴─────────┘

Req/Bytes counts sampled once per second.
# of samples: 10

5k requests in 10.3s, 787 kB read


    여러 원격 서버에 어플 배포하기 위해서 다음을 따라야 합니다
      1. node 어플 싱행하는 n개의 백엔드 서버를 프로비저닝함 (forever과 같은 서비스로)
      2. nginx 가 설치된 로드밸런서 시스템과 트래픽을 n개의 백엔드 서버로 라우팅 하는데 필요한 모든 설정을 프로비저닝함 (실행 가능하도록 준비 - nginx 설정 파일의 upstream 블록에 나열?)
      3. 공개 ip와 공개 도메인이름을 사용해 인터넷에서 로드 밸런서를 공개적으로 사용할 수 있도록...
      4. 브라우저 등의 벤치마킹 ㄷ구를 사용해 로드밸런서의 공개주소로 트래픽 전송
      => 위의 작업 자동화 업체 : Terraform, Ansible, Packer...
      

    
*/